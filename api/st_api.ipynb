{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1pHQkorrSqk53wkg8Qjd91OMfiTzXdVV3","authorship_tag":"ABX9TyMk8s9MzfNTKWvfBRGMLh1V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W3ktgfTYpGeO","executionInfo":{"status":"ok","timestamp":1713618890161,"user_tz":-330,"elapsed":14447,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"bfffa7b4-c0eb-4a94-a1b8-f2ae1f30eef9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q streamlit"]},{"cell_type":"code","source":["!pip install -q tensorflow"],"metadata":{"id":"HDF9RZKYpnlP","executionInfo":{"status":"ok","timestamp":1713618993158,"user_tz":-330,"elapsed":7001,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install -q tensorflow opencv-python matplotlib"],"metadata":{"id":"DUZmIfbZpqaD","executionInfo":{"status":"ok","timestamp":1713619034021,"user_tz":-330,"elapsed":7382,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["%%writefile app.py\n","\n","import os\n","os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n","\n","# import tensorflow as tf\n","\n","import os\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","# import tensorflow as tf\n","\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","import streamlit as st\n","from tensorflow.keras.models import load_model\n","import matplotlib.pyplot as plt\n","\n","# Load the facetracker model\n","# facetracker = load_model(\"face_detector/data/40_facetracker.h5\" )\n","\n","file_path = \"face_detector/data/40_facetracker.h5\"\n","file_path_1 = r\"C:\\Users\\SAGAR KESHAVE\\PycharmProjects\\Face_Detection\\face_detector\\data\\40_facetracker.h5\"\n","\n","facetracker = tf.keras.models.load_model(\n","    \"/content/drive/MyDrive/deep_learning_projects/FaceDetection/model/40_facetracker.h5\", custom_objects=None, compile=True, safe_mode=True\n",")\n","\n","\n","def detect_face(image):\n","    # Resize the image\n","    image = cv2.resize(image, (450, 450))\n","\n","    # Resize using TensorFlow (if required)\n","    resized = tf.image.resize(image, (120, 120))\n","\n","    # Predict using facetracker model\n","    yhat = facetracker.predict(np.expand_dims(resized / 255, 0))\n","\n","    # Extract coordinates from the prediction\n","    sample_coords = yhat[1][0]\n","\n","    # Draw rectangle if face is detected\n","    if yhat[0] > 0.5:\n","        cv2.rectangle(image,\n","                      tuple(np.multiply(sample_coords[:2], [450, 450]).astype(int)),\n","                      tuple(np.multiply(sample_coords[2:], [450, 450]).astype(int)),\n","                      (255, 0, 0), 2)\n","\n","    return image\n","\n","\n","def main():\n","    st.title(\"Face Detection App\")\n","\n","    uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n","\n","    if uploaded_file is not None:\n","        # Read the image\n","        image = cv2.imdecode(np.frombuffer(uploaded_file.read(), np.uint8), 1)\n","\n","        # Detect face\n","        result_image = detect_face(image)\n","\n","        # Display the result\n","        st.image(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB), caption=\"Processed Image\", use_column_width=True)\n","        st.success(\"Face detected!\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvtPyNPIpJ4K","executionInfo":{"status":"ok","timestamp":1713619046385,"user_tz":-330,"elapsed":813,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"0fe3342f-ae74-40ab-ec14-df5d32bcab2c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]},{"cell_type":"code","source":["!npm install localtunnel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y4OMNOi0p4fO","executionInfo":{"status":"ok","timestamp":1713619064128,"user_tz":-330,"elapsed":4611,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"ce6f3594-3e4b-47b4-d404-f2ae15bb58bc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n","\u001b[0m\n","+ localtunnel@2.0.2\n","added 22 packages from 22 contributors and audited 22 packages in 2.42s\n","\n","3 packages are looking for funding\n","  run `npm fund` for details\n","\n","found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n","  run `npm audit fix` to fix them, or `npm audit` for details\n","\u001b[K\u001b[?25h"]}]},{"cell_type":"code","source":["import urllib\n","print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"],"metadata":{"id":"7xcAlEHhrMOW","executionInfo":{"status":"ok","timestamp":1713619397167,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"12defa9d-0713-4c3e-93a5-a7b09b2cd073","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Password/Enpoint IP for localtunnel is: 34.141.135.43\n"]}]},{"cell_type":"code","source":["!streamlit run /content/app.py &>/content/logs.txt &"],"metadata":{"id":"nRAsQ8D4p748","executionInfo":{"status":"ok","timestamp":1713619403005,"user_tz":-330,"elapsed":817,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["!npx localtunnel --port 8501"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L9g5_Fd6qCea","outputId":"c1dd8307-8330-4426-f138-427fdcf7ef7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25hnpx: installed 22 in 3.159s\n","your url is: https://light-women-hug.loca.lt\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"XGf-MfdVqHse"},"execution_count":null,"outputs":[]}]}